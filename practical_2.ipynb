{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c669ff-a233-4034-b7cb-6214df110641",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Text pre-processing & train/test set construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b5dfef-854c-4d9f-8d00-56aec9b1c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72dbe132-8819-46fb-b9b0-92e811ae8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e25b221-70e3-4311-ae07-c5c7f83d6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0598e12b-321c-48d4-b1e9-5b2bf396ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/deceptive_train.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "deceptive_train = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "deceptive_train[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e590d02-e9cc-4659-beec-368f9fd6a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/truthful_train.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "truthful_train = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "truthful_train[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4329389e-0f68-46d8-9aff-25540e2520b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/deceptive_test.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "deceptive_test = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "deceptive_test[\"Label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d026a776-5291-4a41-8166-af556783e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"op_spam_v1.4/negative_polarity/truthful_test.csv\") as f:\n",
    "    lines = [s.replace(\"\\n\", \"\") for s in f.readlines()]\n",
    "\n",
    "truthful_test = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "truthful_test[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4c1da4-006d-4aae-81e3-3da8c0f40f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat deceptive and truthful dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306e899-4798-4ef1-a73a-419dca9e5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([deceptive_train, truthful_train, deceptive_test, truthful_test], axis=0).reset_index(drop=True)\n",
    "df\n",
    "#640-800 = test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68973e-c5ab-40fc-9fd9-9c8158624077",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Further text pre-processing \n",
    "\n",
    "- Tokenization\n",
    "- Lower-casing\n",
    "- Punctuation & Special character removal\n",
    "- Spelling correction\n",
    "- Stop-word removal\n",
    "- (Stemming (Porter)) *Skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78e5ed3-155a-4101-90aa-e535db7ef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # stopwords.words('english')\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ddaafcd-569a-4b58-b898-ce567df33f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in nltk.word_tokenize(x)]) # Tokenize\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word.lower() for word in x]) # Apply lower-casing\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word not in string.punctuation]) # Punctuation removal\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word not in ' '.join(stopwords.words('english'))]) # Stop word removal\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [re.sub(\"(?:\\W|\\d)+\", \"\", word) for word in x]) # Removing special chars and numbers\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [word for word in x if word != \"\"]) # Remove empty strings\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: [str(TextBlob(word).correct()) for word in x]) # Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd04f48-bcba-4d4b-a1cf-4e72ffca5ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hotel, located, mile, train, station, quite, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[made, reservation, hilton, chicago, believing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[people, think, hilton, think, luxury, know, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[husband, recently, stayed, stayed, hilton, ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wife, booked, room, hilton, chicago, three, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  [hotel, located, mile, train, station, quite, ...      0\n",
       "1  [made, reservation, hilton, chicago, believing...      0\n",
       "2  [people, think, hilton, think, luxury, know, w...      0\n",
       "3  [husband, recently, stayed, stayed, hilton, ch...      0\n",
       "4  [wife, booked, room, hilton, chicago, three, w...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle the df. Pickled the df in case the kernel dies when fitting the models, because the spelling correction above takes a while to execute\n",
    "df = pd.read_pickle(\"./df.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fb9867-2cb1-41d2-a4fb-04741db6aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to str to construct dtm with sklearn CountVectorizer\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f813387-d5fb-44d0-9403-0a115976f830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel located mile train station quite like tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>made reservation hilton chicago believing goin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people think hilton think luxury know wish hal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>husband recently stayed stayed hilton chicago ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wife booked room hilton chicago three weekend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  hotel located mile train station quite like tr...      0\n",
       "1  made reservation hilton chicago believing goin...      0\n",
       "2  people think hilton think luxury know wish hal...      0\n",
       "3  husband recently stayed stayed hilton chicago ...      0\n",
       "4  wife booked room hilton chicago three weekend ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a8faa7-6b77-4108-aeb9-15f37c143a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high hopes hilton chicago sad say disappointed outrageous expensive two people one night expect pay park car offer free wife instead pay get internet room wait pm check even though flight morning rent car airport hotel offer transportation stress hilton chicago hotel bar either doubt stay\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Text\"][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97424070-aa83-4d06-9031-a38099a6fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Set ngram=1,1, 1,2 and 2,2 (only bigrams) and min_df (float 0-1) for Naive Bayes when needed (use diff thresholds 0.005 increment starting at 1% -> 10%).\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), min_df=1, lowercase=False)\n",
    "X = vectorizer.fit_transform(df[\"Text\"])\n",
    "# X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d3c544-5217-4f97-ba8e-14700719f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6504)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b341bb-91ec-4072-a0dc-ba6be085f08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abrupt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3d99f-d4ab-48b2-a15e-df0777db4081",
   "metadata": {},
   "source": [
    "#### Seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473e43a0-190f-48c2-977a-dc4e5574d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[0:640], df[\"Label\"][0:640].to_numpy()\n",
    "X_test, y_test = X[640:], df[\"Label\"][640:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62e3b7-4a19-41a4-b4a5-9213d01dae5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Models using unigram only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d5ee94-9774-4956-851a-97b4bb87ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3939a21e-f149-4d43-b9f7-c013040b117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def performance_metrics(y_true, y_pred):\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cf_matrix.ravel()\n",
    "    \n",
    "    accuracy = (tn+tp)/(tn+tp+fp+fn)\n",
    "    recall =  (tp)/(tp+fn)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    \n",
    "    print(cf_matrix)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    \n",
    "    return (accuracy, recall, precision, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56636b49-b51f-47f4-acce-34812e765b87",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79639b76-8ad8-4e17-800e-675f63cd76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d646c6d-c89c-4585-9243-eecaa33ccd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB():\n",
    "    \n",
    "    # Find best threshold\n",
    "    \n",
    "    thresholds = list(range(1,11))\n",
    "    cv_scores = []\n",
    "    for thresh in thresholds:\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,1), min_df=thresh, lowercase=False)\n",
    "        X = vectorizer.fit_transform(df[\"Text\"]) \n",
    "        X_train = X[0:640] # Only need to change X_train/test, y_train/test remains same (only removing/adding columns, not rows)\n",
    "        X_test = X[640:]\n",
    "        score = cross_val_score(MultinomialNB(), X_train, y_train, n_jobs=-1)\n",
    "        cv_scores.append((score.mean(), X_train, X_test, thresh))\n",
    "    \n",
    "    return max(cv_scores, key=lambda x: x[0]) # Return X_train/X_test for which CV score was best (best doc frequency threshold)\n",
    "        \n",
    "best_thresh = NB()  # (score.mean(), X_train, X_test, {ngram: (x,y), min_df: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7426210c-6ed7-4c46-9e0c-e8db6dbc97f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8421875,\n",
       " <640x1601 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 37473 stored elements in Compressed Sparse Row format>,\n",
       " <160x1601 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 8891 stored elements in Compressed Sparse Row format>,\n",
       " 6)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d68fc5a-c2e1-40cc-b305-3c5f058204bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain on whole training set\n",
    "X_train_nb, X_test_nb = best_thresh[1], best_thresh[2]\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_nb, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "46db0a17-fb77-4357-a975-36430033e0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68 12]\n",
      " [12 68]]\n",
      "Accuracy: 0.85\n",
      "Recall: 0.85\n",
      "Precision: 0.85\n",
      "F1: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85, 0.85, 0.85, 0.85)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nb_clf.predict(X_test_nb)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00df3976-6ba8-4544-9492-4b51416cb239",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('nb_uni.pkl', \"wb\")\n",
    "pickle.dump(nb_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbffcbf-9696-4796-af54-a5c61e701296",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d015b34-5bef-44d2-81e5-63ac296e5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97431575-ce82-4db5-a0a6-dd12b42bef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 10, 0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "\n",
    "params = {'C': alphas}\n",
    "\n",
    "lr_clf = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear'), param_grid=params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c4576-39c9-4e2f-a5ff-7199cae003f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "314c6a2e-785c-4e5d-a596-e7731239f7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.64}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c522da67-49c2-4e7e-9a52-5b423eb5f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68 12]\n",
      " [11 69]]\n",
      "Accuracy: 0.86\n",
      "Recall: 0.86\n",
      "Precision: 0.85\n",
      "F1: 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85625, 0.8625, 0.8518518518518519, 0.8571428571428572)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "92c1ea79-65ee-4cdb-97a6-a9efc98bc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('lr_uni.pkl', \"wb\")\n",
    "pickle.dump(lr_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86209090-801f-4097-8ba4-aa7d3d44509c",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a7e9c185-295a-4ff3-8ed1-b75642a8a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e92558aa-f6b0-440f-b91e-3b10528c125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to search\n",
    "alphas = np.arange(0, 10, 0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "alphas = [round(a, 2) for a in alphas]\n",
    "nmin = list(range(2, 21))\n",
    "minleaf = list(range(1, 11))\n",
    "\n",
    "params = {'min_samples_split': nmin, 'min_samples_leaf': minleaf, 'ccp_alpha': alphas}\n",
    "\n",
    "dt_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "845b4069-4c02-477c-a31f-3a9eb8991678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 191140 candidates, totalling 955700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                       0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13,\n",
       "                                       0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2,\n",
       "                                       0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
       "                                       0.28, 0.29, ...],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                               12, 13, 14, 15, 16, 17, 18, 19,\n",
       "                                               20]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "94acf262-326a-41c1-b9d0-0da4b42f1065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.01, 'min_samples_leaf': 6, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5491dab5-64a7-4236-9758-b63ed30e3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('dt_uni.pkl', \"wb\")\n",
    "pickle.dump(dt_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e420410a-6a01-491e-bfb6-ac7290a5a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('dt_uni.pkl', 'rb')\n",
    "dt_clf = pickle.load(_file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa3c0b54-5db1-45d0-b07d-4e624a9d8c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 40]\n",
      " [13 67]]\n",
      "Accuracy: 0.67\n",
      "Recall: 0.84\n",
      "Precision: 0.63\n",
      "F1: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.66875, 0.8375, 0.6261682242990654, 0.7165775401069518)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dt_clf.predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1567d-c049-4caf-ac4b-3bdbd805ef6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f718e70-59ba-49f1-a0d3-95c5a1367905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae1413b7-a576-4560-b1b0-2aea8594bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10000, OOB: 0.81\n"
     ]
    }
   ],
   "source": [
    "nmin = list(range(2, 21))\n",
    "minleaf = list(range(1, 11))\n",
    "ntrees = [50, 100, 200, 300, 500]\n",
    "nfeats = list(range(10, 201, 10))\n",
    "\n",
    "cartesian_product = list(itertools.product(nmin, minleaf, ntrees, nfeats))\n",
    "\n",
    "params = [p for p in cartesian_product if p[1] * 2 <= p[0]]\n",
    "\n",
    "def train_rf(params):\n",
    "    \n",
    "    # Estimate best RF hyperparameters using OOB performance instead of CV\n",
    "    \n",
    "    best_rf_clf = None\n",
    "    i = 0\n",
    "    for p in params:\n",
    "        rf_clf = RandomForestClassifier(n_estimators=p[2], min_samples_split=p[0],\n",
    "                                    min_samples_leaf=p[1], max_features=p[3],\n",
    "                                    oob_score=True, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        \n",
    "        if best_rf_clf is None:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        if rf_clf.oob_score_ > best_rf_clf.oob_score_:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        i+=1\n",
    "        \n",
    "        print(f'Iteration: {i}, OOB: {round(rf_clf.oob_score_, 2)}') \n",
    "    \n",
    "    return (best_rf_clf, best_rf_clf.oob_score_)\n",
    "\n",
    "best_rf_clf = train_rf(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0b7820b-aa77-4f6f-8c7f-ec686778c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ee4432b-f636-4cea-8047-c1fd50117be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(max_features=40, min_samples_leaf=3,\n",
       "                        min_samples_split=12, n_estimators=500, n_jobs=-1,\n",
       "                        oob_score=True),\n",
       " 0.875)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69e17628-1c13-4d6c-982d-9c71c9d1c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('rf_uni.pkl', \"wb\")\n",
    "pickle.dump(best_rf_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "effdb48f-1451-4b2f-8821-e55f93d4d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('rf_uni.pkl', 'rb')\n",
    "rf_clf = pickle.load(_file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78ccba63-2cff-4eea-9181-dcffc9c57d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 14]\n",
      " [ 6 74]]\n",
      "Accuracy: 0.88\n",
      "Recall: 0.93\n",
      "Precision: 0.84\n",
      "F1: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.875, 0.925, 0.8409090909090909, 0.8809523809523809)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf_clf[0].predict(X_test)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ed27d-b795-4e28-8683-ff742c66e5c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Models using bigrams**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffcd90-de44-430e-86fc-03d9afb93f20",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7168e2d-93be-4df2-8388-ec8386aa7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e973961d-ae9e-4a50-a20b-6ab709138b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB():\n",
    "    \n",
    "    # Find best threshold\n",
    "    \n",
    "    thresholds = list(range(1,11))\n",
    "    cv_scores = []\n",
    "    for thresh in thresholds:\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,2), min_df=thresh, lowercase=False)\n",
    "        X = vectorizer.fit_transform(df[\"Text\"]) \n",
    "        X_train = X[0:640] # Only need to change X_train/test, y_train/test remains same (only removing/adding columns, not rows)\n",
    "        X_test = X[640:]\n",
    "        score = cross_val_score(MultinomialNB(), X_train, y_train, n_jobs=-1)\n",
    "        cv_scores.append((score.mean(), X_train, X_test, thresh))\n",
    "    \n",
    "    return max(cv_scores, key=lambda x: x[0]) # Return X_train/X_test for which CV score was best (best doc frequency threshold)\n",
    "        \n",
    "best_thresh = NB()  # (score.mean(), X_train, X_test, {ngram: (x,y), min_df: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cae4a5e6-cddf-4a96-bf4d-3d353db1c881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85,\n",
       " <640x2746 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 45444 stored elements in Compressed Sparse Row format>,\n",
       " <160x2746 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 10849 stored elements in Compressed Sparse Row format>,\n",
       " 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df59dd98-1598-4c36-be22-3ceec09e48ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain on whole training set\n",
    "X_train_nb, X_test_nb = best_thresh[1], best_thresh[2]\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_nb, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbdcb9e2-b27f-4d56-ab50-c5a9e1be21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 17]\n",
      " [ 4 76]]\n",
      "Accuracy: 0.87\n",
      "Recall: 0.95\n",
      "Precision: 0.82\n",
      "F1: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.86875, 0.95, 0.8172043010752689, 0.8786127167630059)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nb_clf.predict(X_test_nb)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb4bcbad-690e-4784-bec0-a971372649b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('nb_bi.pkl', \"wb\")\n",
    "pickle.dump(nb_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73032d6a-3c4a-4391-be79-a1e4a4603f8d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ded425da-0c3f-4ce8-b10a-6287dcc4c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5f6d38dc-e5c1-433b-a77f-7e56ed5654a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 10, 0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "\n",
    "params = {'C': alphas}\n",
    "\n",
    "lr_clf = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear'), param_grid=params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "db9963f8-e130-4d60-b326-07f01461d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bi = CountVectorizer(ngram_range=(1,2), min_df=1, lowercase=False)\n",
    "X_bi = vectorizer_bi.fit_transform(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d90e1fea-50d4-46fc-97dc-bb3d65b5e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr, X_test_lr = X_bi[0:640], X_bi[640:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeccd75-8b6e-40b4-a036-84fed7cd10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train_lr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b8f19df5-de4b-41c2-b869-7c4f4f9ebfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.52}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ff85aa3-f5f3-482f-a925-8d598bf80aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69 11]\n",
      " [ 9 71]]\n",
      "Accuracy: 0.88\n",
      "Recall: 0.89\n",
      "Precision: 0.87\n",
      "F1: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.875, 0.8875, 0.8658536585365854, 0.8765432098765432)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(X_test_lr)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8e9f9b49-fb28-471c-b575-314b3f7781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('lr_bi.pkl', \"wb\")\n",
    "pickle.dump(lr_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9baef759-476a-4748-a4a6-750b1834c5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.52, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_test = LogisticRegression(C=0.52, penalty='l1', solver='liblinear')\n",
    "lr_test.fit(X_train_lr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a66e2bea-1bf2-403e-9aab-3a15ea68339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69 11]\n",
      " [ 9 71]]\n",
      "Accuracy: 0.88\n",
      "Recall: 0.89\n",
      "Precision: 0.87\n",
      "F1: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.875, 0.8875, 0.8658536585365854, 0.8765432098765432)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = lr_test.predict(X_test_lr)\n",
    "performance_metrics(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "42169b0c-5bc8-4870-b9f5-3290ec3905ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1188,  1566,  2128,  2448,  2592,  2607,  3300,  4282,  4539,\n",
       "        4768,  5651,  5670,  5937,  6085,  6604,  6682,  6968,  7589,\n",
       "        7694,  7923,  8040,  8295,  8426,  8643,  8993,  9093,  9193,\n",
       "        9223,  9250,  9568,  9836, 10076, 10417, 10667, 10865, 10964,\n",
       "       11862, 12242, 12381, 12834, 13433, 13906, 14856, 14910, 14967,\n",
       "       15040, 15694, 16004, 16341, 16428, 16591, 17560, 17739, 18332,\n",
       "       18597, 18914, 19098, 19354, 19726, 19872, 20688, 21088, 21466,\n",
       "       22092, 22333, 22547, 22668, 22768, 23020, 23121, 23375, 23757,\n",
       "       24283, 25031, 25992, 26426, 27183, 27498, 27785, 27968, 28505,\n",
       "       28782, 29101, 29336, 29436, 29678, 30095, 30220, 30238, 31074,\n",
       "       31639, 31779, 32056, 32321, 33324, 33431, 33800, 34759, 34981,\n",
       "       35141, 35468, 35632, 35700, 36888, 36910, 37065, 37127, 37602,\n",
       "       37833, 37986, 38573, 38585, 38691, 39004, 39161, 39455, 39505,\n",
       "       39632, 40007, 40085, 40432, 41728, 42009, 42416, 42552, 42908,\n",
       "       43507, 44747, 44900, 44956, 45012, 45197, 45346, 46019, 46381,\n",
       "       47030, 47429, 47818, 48713, 48846, 48915, 49330, 49847, 49928,\n",
       "       50046, 50182, 50349, 50583, 51252, 51427, 51528, 52453, 52926,\n",
       "       53105, 53849, 54116, 54459, 54492, 54627, 54685, 55158, 55428,\n",
       "       55463])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = lr_test.coef_.flatten()\n",
    "nonzero_feature_idxs = lr_test.coef_.flatten().nonzero()[0]\n",
    "nonzero_feature_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "759f0ea1-ca01-474a-a4d8-dee7cafbfd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonzero_feature_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750bd6b-5473-4383-8937-38a0c54e0bdd",
   "metadata": {},
   "source": [
    "Only 163 features non-zero after training LR with lasso penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7390675b-e2cb-4e9f-bd85-bbfcf2648607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.24203991, -0.97158517, -0.93682403, -0.90479762, -0.89272768])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 deceptive\n",
    "top5_deceptive_coeffs = np.sort(coefficients[nonzero_feature_idxs])[0:5]\n",
    "top5_deceptive_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0ef852f3-6259-4d28-8d00-eca6d1737b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23121, 39004, 28782, 8295, 17739]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 deceptive idxs\n",
    "top5_deceptive_idxs = []\n",
    "for coeff in top5_deceptive_coeffs:\n",
    "    top5_deceptive_idxs.append(np.where(coefficients == coeff)[0][0])\n",
    "top5_deceptive_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "18778ed4-35ca-4830-9c5f-78ce262fbb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hotel chicago', 'relax', 'luxury', 'chicago', 'finally'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_bi.get_feature_names_out()[[23121, 39004, 28782, 8295, 17739]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8bff3a40-1290-4136-b62c-dd23d652cd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4309576 , 0.82024089, 0.80038729, 0.73804644, 0.73420736])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 truthful\n",
    "top5_truthful_coeffs = np.sort(coefficients[nonzero_feature_idxs])[-5:][::-1]\n",
    "top5_truthful_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c0678c25-074b-427b-8fc4-28331bac1059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46381, 10417, 47429, 27968, 10865]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 truthful\n",
    "top5_truthful_idxs = []\n",
    "for coeff in top5_truthful_coeffs:\n",
    "    top5_truthful_idxs.append(np.where(coefficients == coeff)[0][0])\n",
    "top5_truthful_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2acf811c-e0dc-4d2c-9ae3-1823feb982b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['star', 'conference', 'street', 'location', 'converge'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_bi.get_feature_names_out()[[46381, 10417, 47429, 27968, 10865]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0701982-52f7-44f2-b623-5388e1ccc5e4",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8fb6798d-cac1-4a4c-9e3f-04d333f5bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cdcbd547-d017-48ab-b7ab-5626b62aeeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to search\n",
    "alphas = np.arange(0, 10, 0.01)\n",
    "alphas = np.append(alphas, [10, 20, 30, 40, 50, 100])\n",
    "alphas = [round(a, 2) for a in alphas]\n",
    "nmin = list(range(2, 21))\n",
    "minleaf = list(range(1, 11))\n",
    "\n",
    "params = {'min_samples_split': nmin, 'min_samples_leaf': minleaf, 'ccp_alpha': alphas}\n",
    "\n",
    "dt_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=params, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b724f281-4366-466b-b209-e4461c8ea566",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bi = CountVectorizer(ngram_range=(1,2), min_df=1, lowercase=False)\n",
    "X_bi = vectorizer_bi.fit_transform(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "11f8297a-ebec-4f7a-89a2-dabdd4bdae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dt, X_test_dt = X_bi[0:640], X_bi[640:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aea8ea4b-37a3-4563-9678-60aadfa76ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 191140 candidates, totalling 955700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                       0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13,\n",
       "                                       0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2,\n",
       "                                       0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
       "                                       0.28, 0.29, ...],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                               12, 13, 14, 15, 16, 17, 18, 19,\n",
       "                                               20]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train_dt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b408af35-e702-4748-b407-5c4fe72eff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.01, 'min_samples_leaf': 9, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ed71a731-70fe-42fc-a03d-64c464330728",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('dt_bi.pkl', \"wb\")\n",
    "pickle.dump(dt_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ff11c023-7583-4e5a-9ac0-d4e9e5a99f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 40]\n",
      " [13 67]]\n",
      "Accuracy: 0.67\n",
      "Recall: 0.84\n",
      "Precision: 0.63\n",
      "F1: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.66875, 0.8375, 0.6261682242990654, 0.7165775401069518)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dt_clf.predict(X_test_dt)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51254466-d3b6-4945-b987-69335880cbd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2590650e-5e06-4482-88d6-70efa7646640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2b68706f-2f3a-4c30-9447-41426891cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24500, OOB: 0.834375\n"
     ]
    }
   ],
   "source": [
    "nmin = list(range(2, 21))\n",
    "minleaf = list(range(1, 11))\n",
    "ntrees = [50, 100, 200, 300, 500]\n",
    "nfeats = list(range(10, 500, 10))\n",
    "\n",
    "cartesian_product = list(itertools.product(nmin, minleaf, ntrees, nfeats))\n",
    "\n",
    "params = [p for p in cartesian_product if p[1] * 2 <= p[0]]\n",
    "\n",
    "def train_rf(p):\n",
    "    \n",
    "    # Estimate best RF hyperparameters using OOB performance instead of CV\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range=(1,2), min_df=1, lowercase=False)\n",
    "    X = vectorizer.fit_transform(df[\"Text\"]) \n",
    "    X_train = X[0:640]\n",
    "    \n",
    "    best_rf_clf = None\n",
    "    i = 0\n",
    "    for p in params:\n",
    "    \n",
    "        rf_clf = RandomForestClassifier(n_estimators=p[2], min_samples_split=p[0],\n",
    "                                    min_samples_leaf=p[1], max_features=p[3],\n",
    "                                    oob_score=True, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "    \n",
    "        if best_rf_clf is None:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        if rf_clf.oob_score_ > best_rf_clf.oob_score_:\n",
    "            best_rf_clf = rf_clf\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        i+=1\n",
    "        \n",
    "        print(f'Iteration: {i}, OOB: {rf_clf.oob_score_}')\n",
    "    \n",
    "    return best_rf_clf\n",
    "\n",
    "\n",
    "best_rf_clf = train_rf(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d680ae91-ea7f-4289-a893-f1021f546620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24500"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b09ce589-388d-4671-bede-514d9eb4ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=200, min_samples_leaf=3,\n",
       "                       min_samples_split=6, n_estimators=500, n_jobs=-1,\n",
       "                       oob_score=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "515b4ac7-aa7f-448c-9508-7ba40dd66aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bi = CountVectorizer(ngram_range=(1,2), min_df=1, lowercase=False)\n",
    "X_bi = vectorizer_bi.fit_transform(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9b2bb2fd-4b4f-4ff1-b94f-6e3982a06094",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rf = X_bi[640:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f84ddc04-783e-41a8-9e0f-29ddcf69288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62 18]\n",
      " [ 6 74]]\n",
      "Accuracy: 0.85\n",
      "Recall: 0.93\n",
      "Precision: 0.80\n",
      "F1: 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85, 0.925, 0.8043478260869565, 0.8604651162790697)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_rf_clf.predict(X_test_rf)\n",
    "performance_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a590f626-9743-4cfc-8dba-35d3721120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file = open('rf_bi.pkl', \"wb\")\n",
    "pickle.dump(best_rf_clf, _file)\n",
    "_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bd027-f7ba-4702-a0f3-f5dc49687b73",
   "metadata": {},
   "source": [
    "## **Statistical significance testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730face5-4b57-4c8c-b883-8f66fdb7c48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
